# -*- coding: utf-8 -*-
"""indian_pines_knnc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1takb8XxxX-AiHkfHk_C8KtjJqCkCu-b_
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

from sklearn import decomposition
from sklearn import datasets

#iniciando a base de dados
#df = pd.read_csv("https://raw.githubusercontent.com/syamkakarla98/Dimensionality-reduction-and-classification-on-Hyperspectral-Images-Using-Python/master/Complete_Data_.csv")
df = pd.read_csv("indian_pines_depois_tsne.csv")
df.head()

#processando as features do dataframe
from sklearn.preprocessing import StandardScaler

ind=[]
#for i in range(200):
    #ind.append('px'+str(i+1))
ind.append('TSNE-1')
ind.append('TSNE-2')

#separando o que vai ser X (dados) e Y (classe)
features = ind
X = df.loc[:, features].values
Y = df.loc[:,['class']].values

#dividindo a base em treino e teste
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
X, Y, test_size = 0.3, random_state = 100)
y_train = y_train.ravel()
y_test = y_test.ravel()
#classifier.fit(X_train, y_train.squeeze())

#importando bibliotecas
from sklearn.neighbors import KNeighborsClassifier  
from sklearn import metrics
import time

#iniciando o KNN Classificador
model = KNeighborsClassifier()
model = KNeighborsClassifier(n_neighbors = 2, weights='uniform', algorithm='auto')
model.fit(X_train, y_train)
start = time.time()
Yhat = model.predict(X_test)
end = time.time()
print('Time Taken For Classification is :',(end - start))
print("Accuracy :",metrics.accuracy_score(Yhat, y_test)*100)
print('\n','*'*11,'Accuracy of INDIAN-PINES Dataset Before Redutor','*'*11)
print('*'*11,' Classifier : K-NEAREST NEIGHBOUR ','*'*11)
ks = []
i=0
start = time.time()
for K in range(100,1000,5):
 K_value = K+1
 neigh = KNeighborsClassifier(n_neighbors = K_value, weights='uniform', algorithm='auto')
 neigh.fit(X_train, y_train) 
 y_pred = neigh.predict(X_test)
 ks.append(metrics.accuracy_score(y_test,y_pred)*100)
 i = i + 1
 print ("#%d"%(i)," - Accuracy is :%1.10f"%(metrics.accuracy_score(y_test,y_pred)*100),"% ","for K-Value: %4d"%(K_value))
end = time.time()

import numpy as np

print(np.mean(ks))
print((end-start)/180)

#grafico da acuracia
import matplotlib.pyplot as plt
plt.plot(ks)
plt.title("Evolução da acuracia")
plt.show()

#resultado da base de teste
dic = {'Classe': y_test, 'Resultado': Yhat}
df_resultado = pd.DataFrame(dic)
df_resultado

#o que acertou e o que errou
acertos = (y_test == Yhat).sum()
erros = 6308 - acertos
print('Acertou: {}\nErrou: {}'.format(acertos, erros))

#matriz de confusão
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

print(confusion_matrix(y_test, Yhat))

!pip install -q scikit-plot

import scikitplot as skplt

skplt.metrics.plot_confusion_matrix(
    y_test, 
    Yhat,
    figsize=(12,12));

#relatório de classificação
print(classification_report(y_test, Yhat))